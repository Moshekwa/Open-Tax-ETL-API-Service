[2025-02-23T11:14:45.884+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-02-23T11:14:45.912+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: open_tax_etl.transform_task manual__2025-02-23T11:14:42.244542+00:00 [queued]>
[2025-02-23T11:14:45.918+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: open_tax_etl.transform_task manual__2025-02-23T11:14:42.244542+00:00 [queued]>
[2025-02-23T11:14:45.919+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2025-02-23T11:14:45.928+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): transform_task> on 2025-02-23 11:14:42.244542+00:00
[2025-02-23T11:14:45.935+0000] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'open_tax_etl', 'transform_task', 'manual__2025-02-23T11:14:42.244542+00:00', '--job-id', '45', '--raw', '--subdir', 'DAGS_FOLDER/opentaxetl.py', '--cfg-path', '/tmp/tmpmpeq4vc8']
[2025-02-23T11:14:45.940+0000] {standard_task_runner.py:91} INFO - Job 45: Subtask transform_task
[2025-02-23T11:14:45.940+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py:62 DeprecationWarning: This process (pid=1603) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-02-23T11:14:45.943+0000] {standard_task_runner.py:64} INFO - Started process 1605 to run task
[2025-02-23T11:14:45.993+0000] {task_command.py:426} INFO - Running <TaskInstance: open_tax_etl.transform_task manual__2025-02-23T11:14:42.244542+00:00 [running]> on host 2cf524a0af0b
[2025-02-23T11:14:46.256+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='open_tax_etl' AIRFLOW_CTX_TASK_ID='transform_task' AIRFLOW_CTX_EXECUTION_DATE='2025-02-23T11:14:42.244542+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-02-23T11:14:42.244542+00:00'
[2025-02-23T11:14:46.257+0000] {taskinstance.py:430} INFO - ::endgroup::
[2025-02-23T11:14:46.280+0000] {logging_mixin.py:188} INFO - Columns in DataFrame: Index(['transaction_id', 'user_id', 'amount', 'transaction_date'], dtype='object')
[2025-02-23T11:14:46.281+0000] {logging_mixin.py:188} INFO - First few rows of DataFrame:
[2025-02-23T11:14:46.289+0000] {logging_mixin.py:188} INFO -    transaction_id  user_id    amount transaction_date
0      TXN204793     1408       0.0       2024-11-07
1      TXN749110     1716       NaN       2024-06-28
2      TXN984574     1934       NaN       2024-09-15
3      TXN180036     1034  -3437.55       10/11/2024
4      TXN147245     1497       0.0       09/12/2024
[2025-02-23T11:14:46.320+0000] {xcom.py:675} ERROR - Object of type Timestamp is not JSON serializable. If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your airflow config or make sure to decorate your object with attr.
[2025-02-23T11:14:46.321+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-02-23T11:14:46.321+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/json.py", line 91, in default
    return serialize(o)
           ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/serialization/serde.py", line 189, in serialize
    raise TypeError(f"cannot serialize object of type {cls}")
TypeError: cannot serialize object of type <class 'pandas._libs.tslibs.timestamps.Timestamp'>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/opentaxetl.py", line 49, in transform_data
    kwargs['ti'].xcom_push(key='transformed_data', value=transformed_data_dict)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3197, in xcom_push
    XCom.set(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/xcom.py", line 246, in set
    value = cls.serialize_value(
            ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/xcom.py", line 673, in serialize_value
    return json.dumps(value, cls=XComEncoder).encode("UTF-8")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/json.py", line 104, in encode
    return super().encode(o)
           ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/json/encoder.py", line 200, in encode
    chunks = self.iterencode(o, _one_shot=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/json/encoder.py", line 258, in iterencode
    return _iterencode(o, 0)
           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/json.py", line 93, in default
    return super().default(o)
           ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type Timestamp is not JSON serializable
[2025-02-23T11:14:46.334+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=open_tax_etl, task_id=transform_task, run_id=manual__2025-02-23T11:14:42.244542+00:00, execution_date=20250223T111442, start_date=20250223T111445, end_date=20250223T111446
[2025-02-23T11:14:46.341+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 45 for task transform_task (Object of type Timestamp is not JSON serializable; 1605)
[2025-02-23T11:14:46.380+0000] {local_task_job_runner.py:243} INFO - Task exited with return code 1
[2025-02-23T11:14:46.393+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-23T11:14:46.394+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
